%% LyX 2.3.5.2 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[spanish,english]{article}
\usepackage[T1]{fontenc}
\usepackage[latin9]{luainputenc}
\usepackage{graphicx}
\usepackage{babel}
\addto\shorthandsspanish{\spanishdeactivate{~<>}}

\begin{document}
\title{Chapter 4 The Language Instinct How the Mind Creates Language by Steven
Pinker}
\date{Date 09/25/20}
\author{\selectlanguage{spanish}%
Andrei León Salas\pagebreak}

\maketitle
\tableofcontents{}\pagebreak{}

\section{Summary\index{Summary}}

Pinker starts explaining that language has the ability to explain
different things, as who did the action, who were affected, how the
action was done, etc. He used a interesting example about putting
the same words in different order has a different essence, a dog bites
a man, a man bites a dog.

There are 2 principles that explains this. The first one articulated
by Ferdinand de Saussure, is named ``the arbitrariness of the sign''
. The word that represents the dog is the same as the dog in the English
language, being able to convey the person who reads/hears the word.

The second one is captured by Wilhelm Von Humboldt in the next phrase:
language makes infinite use of finite media, we know the difference
in that sentence because the order of where the dog is, even with
the same finite media, we can create infinite types of sentences because
of that.

Pinker says that then, language works as we have a lexicon of words
and concepts, and then a set of rules in order to combine those words
to create relationships between them. Creating infinite number of
combinations thanks to that. Also because of that grammar is a code
that is autonomous from cognition. Ungrammar sentences are simply
strange for us because we need to interpret that, the opposite is
also true, grammatical sentences can be correct, but we feel that
the interpretation is wrong, or at least, not the same as the one
who created that.

It happens too in computer programs, where grammatical input has to
be 100\% correct or it can not interpret it. An example is The Tin
Men, where there is a word-chain device where the is a lists of words,
and a set of directions, creating sentences from word to word, being
a really simple example of a discrete combination system, using a
finite set of words in order to create a infinite number of combinations,
demonstrating the first concept. This is not different of how the
human brain works, we have a infinite list of words, that we chain
word after word in order to create a sentence and creating an stimulus
to other human begin and generating their own interpretation and reaction,
that could be the exactly same thing, a chain of words base of their
own list of words. People learn first the words, but not the rules
on what word comes next, but with experience he records what word
can come after which next word, doing base of category (not words)
and later the rules of how nouns and verbs and adjectives can not
go all in the same sentence, slowly learning every different rule
until creating a big complex system of rules.

But Chomsky refuted this idea, he proved that some sentences in English
can not be generated by a word-chain device, as they only remembers
their last state, not all the other words that came before. 

He shows that we as the mortals that we are, we can process long deep
dependencies that word-chain can not, like in this sentence: \textquotedbl Daddy,
what did you bring that book that I don't want to be read to out of
up for?\textquotedbl . Junior decided to not use for dependencies:
to, out, up and for, needed in the different grammar parts: to be
read, that book that, brings and up. I

Pinker uses ``Only God can make a tree'' as an example, where a
sentence is not a chain, instead is a tree, where their branches can
be joined with others to create a even greater tree. Linking happens
thanks to the set of grammar rules, and eliminates the problem of
word-chain devices. Also as they are modular they can also be un-joined
and joined in another place and still have meaning. He goes really
deep explaining specific cases all along, some of them are difficult
to follow as they are English heavily focused, but really interesting
as he demonstrated how a word-chain can not compete with the language
how the human begin interprets it.

Pinker points out that grouping words into phrases is necessary to
connect the sentences with their meaning. We can know who is the one
performing the action because the phrase is together, like in the
ice cream example: \includegraphics[width=0.7\columnwidth]{\string"the girl eats ice cream\string".eps}

We know that the sentence is about the girl eating ice cream because
is attach together, and the boy is the one eating hot dogs because
is tied together, but the word-chain machine could not see this ans
would mixed it out as eats ice cream can go after either the boy or
the girl. 

Another example he takes is from chapter 3, where he points out that
a word can have multiple meanings, or even a complete sentence can
have to meanings in a specific word, just because all the sentence
is different. But a word-chain device could not see this as it can
not group together complete phrases.

Pinker empathizes that even our grammar teacher has some of the basics
not as good as it could be. An specific example are that Noun's are
the name of any thing, and most of them are names of persons, places
and things, but he shows how there are many other nouns used in different
context like:

the destruction of the city, the way to san jose, etc, where the nouns
are not names, instead it means something different like an actions
or a patch and not their specific things. 

Something interesting about trees and branches, is that is common
in all phrases in all the world's languages, and not something exclusive
of the English language. He explains how nouns phrases and verb phrases
have a lot of similarities, a head which gives the phrase its name
and determines what it is about, some role players grouped with the
head inside a sub phrase, modifiers outside the sub phrase and a subject,
implying that there are super general rules instead of the vast of
specific rules the English grammar has. And this general rule extends
to other languages like Japanese that is like a glass version of the
English rules, even as they are not associated at all, implying again
how a super rule could be behind all the other rules.

There are also some expectations to the super rules. Pinker explains
a really deep example on how some nouns needs to have a case tag but
other have it impossible even if the super rules accepts it. 

Pinker also explains how a sentence is the most important as it is
the most atomic part that can be either true or false. A word can
not be false as it only means a thing, but a sentence explains extend
the meaning of it. 

He closes the chapter saying that as he dissected syntax, he expects
from us that we react in a positive way, learning all the deep things
language have and how important is to understand it from the inside. 

\pagebreak{}

\section{Personal Opinion\index{Opinion}}

Now i understand how and why this books connects with programming
languages. In the project we have to do some specific grammars and
trees using the scanner and the parses, being almost the same but
instead begin more specific as it is a computer program. Also how
well fits the infinite use of finite media, we can do infinite amount
of things, using the finite amount of functions, properties and variables
we have in a language. I really liked how he explain it and agree
on how language work, but i feel strange about the general rule as
i only know 2 languages. I can see the general rules with the DFA
we view in classes, as an autonomous use general rules in order to
compile different languages, is it the same here, some general rules
(that could have really specific exceptions) applies to English and
Japanese at the same time
\end{document}
